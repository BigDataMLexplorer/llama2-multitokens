{
  "os":  "Windows-10-10.0.26100-SP0",
  "python":  "CPython 3.11.5",
  "startedAt":  "2025-03-22T18:33:36.499441Z",
  "args":  [
    "--n_future=4",
    "--out_dir=outmini",
    "--batch_size=2",
    "--max_seq_len=512",
    "--gradient_accumulation_steps=1",
    "--vocab_source=custom",
    "--vocab_size=512",
    "--dim=64",
    "--n_layers=5",
    "--n_heads=8",
    "--n_kv_heads=4",
    "--multiple_of=4",
    "--learning_rate=1.56e-5",
    "--dropout=0.05",
    "--weight_decay=0.01",
    "--max_iters=2000",
    "--beta2=0.99",
    "--warmup_iters=1000",
    "--eval_interval=250",
    "--eval_iters=50",
    "--compile=False",
    "--device=cpu",
    "--dtype=float32",
    "--log_interval=20",
    "--wandb_log=True",
    "--wandb_project=Llama2.c",
    "--wandb_run_name=multi_token_cpu2"
  ],
  "program":  "C:\\Users\\uzivatel\\Desktop\\llama2.c\\train.py",
  "codePath":  "train.py",
  "git":  {
    "remote":  "https://github.com/karpathy/llama2.c.git",
    "commit":  "350e04fe35433e6d2941dce5a1f53308f87058eb"
  },
  "email":  "r8man012@gmail.com",
  "root":  "C:\\Users\\uzivatel\\Desktop\\llama2.c",
  "host":  "DESKTOP-9NK86FP",
  "executable":  "C:\\Users\\uzivatel\\anaconda3\\python.exe",
  "codePathLocal":  "train.py",
  "cpu_count":  4,
  "cpu_count_logical":  8,
  "gpu":  "NVIDIA GeForce GTX 1050",
  "gpu_count":  1,
  "disk":  {
    "/":  {
      "total":  "1023187873792",
      "used":  "233305169920"
    }
  },
  "memory":  {
    "total":  "14901669888"
  },
  "cpu":  {
    "count":  4,
    "countLogical":  8
  },
  "gpu_nvidia":  [
    {
      "name":  "NVIDIA GeForce GTX 1050",
      "memoryTotal":  "3221225472",
      "cudaCores":  768,
      "architecture":  "Pascal"
    }
  ],
  "cudaVersion":  "12.6"
}